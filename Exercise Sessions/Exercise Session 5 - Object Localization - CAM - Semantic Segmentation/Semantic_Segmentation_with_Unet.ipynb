{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoeDebrois/Artificial-NN-and-Deep-Learning/blob/main/Semantic_Segmentation_with_Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdM1FKc-AWij",
      "metadata": {
        "id": "bdM1FKc-AWij"
      },
      "source": [
        "# Artificial Neural Networks and Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "## Lecture 5b: Semantic Segmentation with UNet\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1HIFUP4_SABD57IjB2f4DNRekCZlPWi5k\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb2Nqybr7r9m",
      "metadata": {
        "id": "eb2Nqybr7r9m"
      },
      "source": [
        "## üåê Connect Colab to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8lGg13S_7tv4",
      "metadata": {
        "id": "8lGg13S_7tv4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2024-2025] AN2DL/Lecture 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hlZgYZ6i7ute",
      "metadata": {
        "id": "hlZgYZ6i7ute"
      },
      "source": [
        "## ‚öôÔ∏è Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6IpcjgO07x6U",
      "metadata": {
        "id": "6IpcjgO07x6U"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Import TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "\n",
        "# Set seed for TensorFlow\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Reduce TensorFlow verbosity\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Print TensorFlow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Import other libraries\n",
        "import os\n",
        "import math\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XkmAUQjyLRM4",
      "metadata": {
        "id": "XkmAUQjyLRM4"
      },
      "source": [
        "## ‚è≥ Load and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rL8Qr7_5LLq9",
      "metadata": {
        "id": "rL8Qr7_5LLq9"
      },
      "outputs": [],
      "source": [
        "# Set environment variables for Cityscapes dataset\n",
        "os.environ[\"DATASET_NAME\"] = \"cityscapes_data.zip\"\n",
        "os.environ[\"DATASET_URL\"] = \"15IEOX3K-VKVJFLQ9BfN0edxXzTVuwxz1\"\n",
        "\n",
        "# Check if Cityscapes dataset exists, download and unzip if not\n",
        "if not os.path.exists(os.environ[\"DATASET_NAME\"]):\n",
        "    print(\"Downloading Cityscapes dataset...\")\n",
        "    !gdown -q ${DATASET_URL} -O ${DATASET_NAME}\n",
        "    print(\"Cityscapes dataset downloaded!\")\n",
        "\n",
        "    print(\"Unzipping Cityscapes dataset...\")\n",
        "    !unzip -o ${DATASET_NAME}\n",
        "    print(\"Cityscapes dataset unzipped!\")\n",
        "else:\n",
        "    print(\"Cityscapes dataset already downloaded and unzipped. Using cached data.\")\n",
        "\n",
        "# Set environment variables for Cityscapes labels\n",
        "os.environ[\"LABELS_NAME\"] = \"cityscapes_labels.zip\"\n",
        "os.environ[\"LABELS_URL\"] = \"1rgf0ntbqFD6wkIT_P_1okmxxmwYt9lqo\"\n",
        "\n",
        "# Check if Cityscapes labels exist, download and unzip if not\n",
        "if not os.path.exists(os.environ[\"LABELS_NAME\"]):\n",
        "    print(\"Downloading Cityscapes labels...\")\n",
        "    !gdown -q ${LABELS_URL} -O ${LABELS_NAME}\n",
        "    print(\"Cityscapes labels downloaded!\")\n",
        "\n",
        "    print(\"Unzipping Cityscapes labels...\")\n",
        "    !unzip -o ${LABELS_NAME}\n",
        "    print(\"Cityscapes labels unzipped!\")\n",
        "else:\n",
        "    print(\"Cityscapes labels already downloaded and unzipped. Using cached data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bGTLiT7yygcR",
      "metadata": {
        "id": "bGTLiT7yygcR"
      },
      "outputs": [],
      "source": [
        "# Set batch size for training\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Set learning rate for the optimiser\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "# Set early stopping patience threshold\n",
        "PATIENCE = 30\n",
        "\n",
        "# Set maximum number of training epochs\n",
        "EPOCHS = 1000\n",
        "\n",
        "# Set data split size for training and validation\n",
        "SPLITS_SIZE = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LMElfeouygZp",
      "metadata": {
        "id": "LMElfeouygZp"
      },
      "outputs": [],
      "source": [
        "# Load image and label paths\n",
        "print(\"Loading file paths...\")\n",
        "image_paths = sorted([os.path.join('data', f) for f in os.listdir('data')])\n",
        "label_paths = sorted([os.path.join('labels', f) for f in os.listdir('labels')])\n",
        "print(\"File paths loaded!\")\n",
        "\n",
        "# Display some examples of paths\n",
        "print(\"\\nFirst 5 image paths:\", image_paths[:5])\n",
        "print(\"First 5 label paths:\", label_paths[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6w9C5huBygXN",
      "metadata": {
        "id": "6w9C5huBygXN"
      },
      "outputs": [],
      "source": [
        "# Split the paths (not the data) into training, validation, and test sets\n",
        "print(\"Splitting data...\")\n",
        "train_val_img, test_img, train_val_lbl, test_lbl = train_test_split(\n",
        "    image_paths, label_paths, test_size=SPLITS_SIZE, random_state=seed\n",
        ")\n",
        "train_img, val_img, train_lbl, val_lbl = train_test_split(\n",
        "    train_val_img, train_val_lbl, test_size=SPLITS_SIZE, random_state=seed\n",
        ")\n",
        "print(\"Data splitted!\")\n",
        "\n",
        "print(f\"\\nNumber of images:\")\n",
        "print(f\"Train: {len(train_img)}\")\n",
        "print(f\"Validation: {len(val_img)}\")\n",
        "print(f\"Test: {len(test_img)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WVnWhprMHJ9q",
      "metadata": {
        "id": "WVnWhprMHJ9q"
      },
      "outputs": [],
      "source": [
        "# Define whether to use the simple or detailed version\n",
        "simple_version = True\n",
        "\n",
        "# Define the category mapping\n",
        "if simple_version:\n",
        "    category_map = {\n",
        "        0: 0,  # unlabelled\n",
        "        1: 0,  # static\n",
        "        2: 0,  # ground\n",
        "        3: 1,  # road\n",
        "        4: 1,  # sidewalk\n",
        "        5: 1,  # parking\n",
        "        6: 1,  # rail track\n",
        "        7: 2,  # building\n",
        "        8: 2,  # wall\n",
        "        9: 2,  # fence\n",
        "        10: 2, # guard rail\n",
        "        11: 2, # bridge\n",
        "        12: 2, # tunnel\n",
        "        13: 3, # pole\n",
        "        15: 3, # traffic light\n",
        "        16: 3, # traffic sign\n",
        "        17: 4, # vegetation\n",
        "        18: 4, # terrain\n",
        "        19: 5, # sky\n",
        "        20: 6, # person\n",
        "        21: 6, # rider\n",
        "        22: 7, # car\n",
        "        23: 7, # truck\n",
        "        24: 7, # bus\n",
        "        25: 7, # caravan\n",
        "        26: 7, # trailer\n",
        "        27: 7, # train\n",
        "        28: 7, # motorcycle\n",
        "        29: 7, # bicycle\n",
        "    }\n",
        "else:\n",
        "    category_map = {\n",
        "        0: 0,  # unlabelled\n",
        "        1: 1,  # static\n",
        "        2: 2,  # ground\n",
        "        3: 3,  # road\n",
        "        4: 4,  # sidewalk\n",
        "        5: 5,  # parking\n",
        "        6: 6,  # rail track\n",
        "        7: 7,  # building\n",
        "        8: 8,  # wall\n",
        "        9: 9,  # fence\n",
        "        10: 10, # guard rail\n",
        "        11: 11, # bridge\n",
        "        12: 12, # tunnel\n",
        "        13: 13, # pole\n",
        "        15: 14, # traffic light\n",
        "        16: 15, # traffic sign\n",
        "        17: 16, # vegetation\n",
        "        18: 17, # terrain\n",
        "        19: 18, # sky\n",
        "        20: 19, # person\n",
        "        21: 20, # rider\n",
        "        22: 21, # car\n",
        "        23: 22, # truck\n",
        "        24: 23, # bus\n",
        "        25: 24, # caravan\n",
        "        26: 25, # trailer\n",
        "        27: 26, # train\n",
        "        28: 27, # motorcycle\n",
        "        29: 28, # bicycle\n",
        "    }\n",
        "\n",
        "\n",
        "# Calculate the correct number of classes after mapping\n",
        "NUM_CLASSES = len(set(category_map.values()))\n",
        "print(f\"Number of original categories: {len(category_map)}\")\n",
        "print(f\"Number of classes after mapping: {NUM_CLASSES}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wvqFgT7pygSf",
      "metadata": {
        "id": "wvqFgT7pygSf"
      },
      "outputs": [],
      "source": [
        "def load_single_image(image_path, label_path, input_size=(64, 128)):\n",
        "    \"\"\"\n",
        "    Load a single image-label pair with the correct shape.\n",
        "    \"\"\"\n",
        "    # Read and preprocess the image\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.io.decode_png(image, channels=3)  # Ensure 3 channels\n",
        "    image = tf.image.resize(image, input_size)   # Resize to fixed size\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "    # Read and preprocess the label\n",
        "    label = tf.io.read_file(label_path)\n",
        "    label = tf.io.decode_png(label, channels=1)  # Ensure single channel\n",
        "    label = tf.image.resize(label, input_size, method='bilinear')  # Resize to fixed size\n",
        "    label = tf.cast(label, tf.int32)\n",
        "\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m7CfNte5mleo",
      "metadata": {
        "id": "m7CfNte5mleo"
      },
      "outputs": [],
      "source": [
        "def apply_category_mapping(label):\n",
        "    \"\"\"\n",
        "    Apply category mapping to labels.\n",
        "    \"\"\"\n",
        "    keys_tensor = tf.constant(list(category_map.keys()), dtype=tf.int32)\n",
        "    vals_tensor = tf.constant(list(category_map.values()), dtype=tf.int32)\n",
        "    table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(keys_tensor, vals_tensor),\n",
        "        default_value=0\n",
        "    )\n",
        "    return table.lookup(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qvbEqWpDygP3",
      "metadata": {
        "id": "qvbEqWpDygP3"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def random_flip(image, label, seed=None):\n",
        "    \"\"\"Consistent random horizontal flip.\"\"\"\n",
        "    if seed is None:\n",
        "        seed = np.random.randint(0, 1000000)\n",
        "    flip_prob = tf.random.uniform([], seed=seed)\n",
        "    image = tf.cond(\n",
        "        flip_prob > 0.5,\n",
        "        lambda: tf.image.flip_left_right(image),\n",
        "        lambda: image\n",
        "    )\n",
        "    label = tf.cond(\n",
        "        flip_prob > 0.5,\n",
        "        lambda: tf.image.flip_left_right(label),\n",
        "        lambda: label\n",
        "    )\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cL0Nf8teywO5",
      "metadata": {
        "id": "cL0Nf8teywO5"
      },
      "outputs": [],
      "source": [
        "def make_dataset(image_paths, label_paths, batch_size, shuffle=True, augment=False, seed=None):\n",
        "    \"\"\"\n",
        "    Create a memory-efficient TensorFlow dataset.\n",
        "    \"\"\"\n",
        "    # Create dataset from file paths\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, label_paths))\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.shuffle(buffer_size=batch_size * 2, seed=seed)\n",
        "\n",
        "    # Load images and labels\n",
        "    dataset = dataset.map(\n",
        "        load_single_image,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    # Apply category mapping\n",
        "    dataset = dataset.map(\n",
        "        lambda x, y: (x, apply_category_mapping(y)),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    if augment:\n",
        "        dataset = dataset.map(\n",
        "            lambda x, y: random_flip(x, y, seed=seed),\n",
        "            num_parallel_calls=tf.data.AUTOTUNE\n",
        "        )\n",
        "\n",
        "    # Batch the data\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=False)\n",
        "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aF8y7CjoywL_",
      "metadata": {
        "id": "aF8y7CjoywL_"
      },
      "outputs": [],
      "source": [
        "# Create the datasets\n",
        "print(\"Creating datasets...\")\n",
        "train_dataset = make_dataset(\n",
        "    train_img, train_lbl,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    augment=True,\n",
        "    seed=seed\n",
        ")\n",
        "\n",
        "val_dataset = make_dataset(\n",
        "    val_img, val_lbl,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_dataset = make_dataset(\n",
        "    test_img, test_lbl,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")\n",
        "print(\"Datasets created!\")\n",
        "\n",
        "# Check the shape of the data\n",
        "for images, labels in train_dataset.take(1):\n",
        "    input_shape = images.shape[1:]\n",
        "    print(f\"\\nInput shape: {input_shape}\")\n",
        "    print(\"Images shape:\", images.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "    print(\"Labels dtype:\", labels.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zd3C28U1ywJM",
      "metadata": {
        "id": "Zd3C28U1ywJM"
      },
      "outputs": [],
      "source": [
        "def create_segmentation_colormap(num_classes):\n",
        "    \"\"\"\n",
        "    Create a linear colormap using a predefined palette.\n",
        "    Uses 'viridis' as default because it is perceptually uniform\n",
        "    and works well for colorblindness.\n",
        "    \"\"\"\n",
        "    return plt.cm.viridis(np.linspace(0, 1, num_classes))\n",
        "\n",
        "def apply_colormap(label, colormap=None):\n",
        "    \"\"\"\n",
        "    Apply the colormap to a label.\n",
        "    \"\"\"\n",
        "    # Ensure label is 2D\n",
        "    label = np.squeeze(label)\n",
        "\n",
        "    if colormap is None:\n",
        "        num_classes = len(np.unique(label))\n",
        "        colormap = create_segmentation_colormap(num_classes)\n",
        "\n",
        "    # Apply the colormap\n",
        "    colored = colormap[label.astype(int)]\n",
        "\n",
        "    return colored\n",
        "\n",
        "def plot_sample_batch(dataset, num_samples=3):\n",
        "    \"\"\"\n",
        "    Display some image and label pairs from the dataset.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 4*num_samples))\n",
        "\n",
        "    for images, labels in dataset.take(1):\n",
        "        labels_np = labels.numpy()\n",
        "        num_classes = len(np.unique(labels_np))\n",
        "        colormap = create_segmentation_colormap(num_classes)\n",
        "\n",
        "        for j in range(min(num_samples, len(images))):\n",
        "            # Plot original image\n",
        "            plt.subplot(num_samples, 2, j*2 + 1)\n",
        "            plt.imshow(images[j])\n",
        "            plt.title(f'Image {j+1}')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot colored label\n",
        "            plt.subplot(num_samples, 2, j*2 + 2)\n",
        "            colored_label = apply_colormap(labels_np[j], colormap)\n",
        "            plt.imshow(colored_label)\n",
        "            plt.title(f'Label {j+1}')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "# Visualize examples from the training set\n",
        "print(\"Visualizing examples from the training set:\")\n",
        "plot_sample_batch(train_dataset, num_samples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1MdeusJwgLROcAFeBEcXvmMzGSy4SGxfG\" width=\"900\"/>"
      ],
      "metadata": {
        "id": "8jNvlVTxegGV"
      },
      "id": "8jNvlVTxegGV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Models and Experiments"
      ],
      "metadata": {
        "id": "lGKs0aKsfZrj"
      },
      "id": "lGKs0aKsfZrj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h5M17nxkywGh",
      "metadata": {
        "id": "h5M17nxkywGh"
      },
      "outputs": [],
      "source": [
        "def unet_block(input_tensor, filters, kernel_size=3, activation='relu', stack=2, name=''):\n",
        "    # Initialise the input tensor\n",
        "    x = input_tensor\n",
        "\n",
        "    # Apply a sequence of Conv2D, Batch Normalisation, and Activation layers for the specified number of stacks\n",
        "    for i in range(stack):\n",
        "        x = tfkl.Conv2D(filters, kernel_size=kernel_size, padding='same', name=name + 'conv' + str(i + 1))(x)\n",
        "        x = tfkl.BatchNormalization(name=name + 'bn' + str(i + 1))(x)\n",
        "        x = tfkl.Activation(activation, name=name + 'activation' + str(i + 1))(x)\n",
        "\n",
        "    # Return the transformed tensor\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RuEAFQKoywD1",
      "metadata": {
        "id": "RuEAFQKoywD1"
      },
      "outputs": [],
      "source": [
        "def get_unet_model(input_shape=(64, 128, 3), num_classes=NUM_CLASSES, seed=seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    # Downsampling path\n",
        "    down_block_1 = unet_block(input_layer, 32, name='down_block1_')\n",
        "    d1 = tfkl.MaxPooling2D()(down_block_1)\n",
        "\n",
        "    down_block_2 = unet_block(d1, 64, name='down_block2_')\n",
        "    d2 = tfkl.MaxPooling2D()(down_block_2)\n",
        "\n",
        "    # Bottleneck\n",
        "    bottleneck = unet_block(d2, 128, name='bottleneck')\n",
        "\n",
        "    # Upsampling path\n",
        "    u1 = tfkl.UpSampling2D()(bottleneck)\n",
        "    u1 = tfkl.Concatenate()([u1, down_block_2])\n",
        "    u1 = unet_block(u1, 64, name='up_block1_')\n",
        "\n",
        "    u2 = tfkl.UpSampling2D()(u1)\n",
        "    u2 = tfkl.Concatenate()([u2, down_block_1])\n",
        "    u2 = unet_block(u2, 32, name='up_block2_')\n",
        "\n",
        "    # Output Layer\n",
        "    output_layer = tfkl.Conv2D(num_classes, kernel_size=1, padding='same', activation=\"softmax\", name='output_layer')(u2)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='UNet')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IhLIsPLJ1dUf",
      "metadata": {
        "id": "IhLIsPLJ1dUf"
      },
      "outputs": [],
      "source": [
        "model = get_unet_model()\n",
        "\n",
        "# Print a detailed summary of the model with expanded nested layers and trainable parameters.\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "# Generate and display a graphical representation of the model architecture.\n",
        "tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zD1Ohgjo1dSO",
      "metadata": {
        "id": "zD1Ohgjo1dSO"
      },
      "outputs": [],
      "source": [
        "# Define custom Mean Intersection Over Union metric\n",
        "class MeanIntersectionOverUnion(tf.keras.metrics.MeanIoU):\n",
        "    def __init__(self, num_classes, labels_to_exclude=None, name=\"mean_iou\", dtype=None):\n",
        "        super(MeanIntersectionOverUnion, self).__init__(num_classes=num_classes, name=name, dtype=dtype)\n",
        "        if labels_to_exclude is None:\n",
        "            labels_to_exclude = [0]  # Default to excluding label 0\n",
        "        self.labels_to_exclude = labels_to_exclude\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Convert predictions to class labels\n",
        "        y_pred = tf.math.argmax(y_pred, axis=-1)\n",
        "\n",
        "        # Flatten the tensors\n",
        "        y_true = tf.reshape(y_true, [-1])\n",
        "        y_pred = tf.reshape(y_pred, [-1])\n",
        "\n",
        "        # Apply mask to exclude specified labels\n",
        "        for label in self.labels_to_exclude:\n",
        "            mask = tf.not_equal(y_true, label)\n",
        "            y_true = tf.boolean_mask(y_true, mask)\n",
        "            y_pred = tf.boolean_mask(y_pred, mask)\n",
        "\n",
        "        # Update the state\n",
        "        return super().update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "# Visualization callback\n",
        "class VizCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, image_path, label_path, frequency=5):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.frequency = frequency\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch % self.frequency == 0:  # Visualize only every \"frequency\" epochs\n",
        "            image, label = load_single_image(self.image_path, self.label_path)\n",
        "            label = apply_category_mapping(label)\n",
        "            image = tf.expand_dims(image, 0)\n",
        "            pred = self.model.predict(image, verbose=0)\n",
        "            y_pred = tf.math.argmax(pred, axis=-1)\n",
        "            y_pred = y_pred.numpy()\n",
        "\n",
        "            # Create colormap\n",
        "            num_classes = NUM_CLASSES\n",
        "            colormap = create_segmentation_colormap(num_classes)\n",
        "\n",
        "            plt.figure(figsize=(16, 4))\n",
        "\n",
        "            # Input image\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(image[0])\n",
        "            plt.title(\"Input Image\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Ground truth\n",
        "            plt.subplot(1, 3, 2)\n",
        "            colored_label = apply_colormap(label.numpy(), colormap)\n",
        "            plt.imshow(colored_label)\n",
        "            plt.title(\"Ground Truth Mask\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Prediction\n",
        "            plt.subplot(1, 3, 3)\n",
        "            colored_pred = apply_colormap(y_pred[0], colormap)\n",
        "            plt.imshow(colored_pred)\n",
        "            plt.title(\"Predicted Mask\")\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tSlLo9Mx1dPr",
      "metadata": {
        "id": "tSlLo9Mx1dPr"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "print(\"Compiling model...\")\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.AdamW(LEARNING_RATE),\n",
        "    metrics=[\"accuracy\", MeanIntersectionOverUnion(num_classes=NUM_CLASSES, labels_to_exclude=[0])]\n",
        ")\n",
        "print(\"Model compiled!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H6J65MMp4pA8",
      "metadata": {
        "id": "H6J65MMp4pA8"
      },
      "outputs": [],
      "source": [
        "# Setup callbacks\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    patience=PATIENCE,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "viz_callback = VizCallback(val_img[0], val_lbl[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oXLduy0m1dNQ",
      "metadata": {
        "id": "oXLduy0m1dNQ"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_dataset,\n",
        "    callbacks=[early_stopping, viz_callback],\n",
        "    verbose=1\n",
        ").history\n",
        "\n",
        "# Calculate and print the final validation accuracy\n",
        "final_val_meanIoU = round(max(history['val_mean_iou'])* 100, 2)\n",
        "print(f'Final validation Mean Intersection Over Union: {final_val_meanIoU}%')\n",
        "\n",
        "# Save the trained model to a file with the accuracy included in the filename\n",
        "model_filename = 'UNet_'+str(final_val_meanIoU)+'.keras'\n",
        "model.save(model_filename)\n",
        "\n",
        "# Delete the model to free up resources\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wBxIwurlyv6N",
      "metadata": {
        "id": "wBxIwurlyv6N"
      },
      "outputs": [],
      "source": [
        "# Plot and display training and validation loss\n",
        "plt.figure(figsize=(18, 3))\n",
        "plt.plot(history['loss'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
        "plt.plot(history['val_loss'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
        "plt.title('Cross Entropy')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Plot and display training and validation accuracy\n",
        "plt.figure(figsize=(18, 3))\n",
        "plt.plot(history['accuracy'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
        "plt.plot(history['val_accuracy'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Plot and display training and validation mean IoU\n",
        "plt.figure(figsize=(18, 3))\n",
        "plt.plot(history['mean_iou'], label='Training', alpha=0.8, color='#ff7f0e', linewidth=2)\n",
        "plt.plot(history['val_mean_iou'], label='Validation', alpha=0.9, color='#5a9aa5', linewidth=2)\n",
        "plt.title('Mean Intersection over Union')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üïπÔ∏è Use the Model - Make Inference"
      ],
      "metadata": {
        "id": "PVvA415Ifll8"
      },
      "id": "PVvA415Ifll8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-j7J_CT9yv3o",
      "metadata": {
        "id": "-j7J_CT9yv3o"
      },
      "outputs": [],
      "source": [
        "# Load UNet model without compiling\n",
        "model = tfk.models.load_model('UNet_59.26.keras', compile=False)\n",
        "\n",
        "# Compile the model with specified loss, optimizer, and metrics\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tfk.optimizers.AdamW(LEARNING_RATE),\n",
        "    metrics=[\"accuracy\", MeanIntersectionOverUnion(num_classes=NUM_CLASSES, labels_to_exclude=[0])]\n",
        ")\n",
        "\n",
        "# Print a detailed summary of the model with expanded nested layers and trainable parameters.\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "# Generate and display a graphical representation of the model architecture.\n",
        "tf.keras.utils.plot_model(model, show_trainable=True, expand_nested=True, dpi=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "llxsc8cPyv1P",
      "metadata": {
        "id": "llxsc8cPyv1P"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set and print the results\n",
        "test_loss, test_accuracy, test_mean_iou = model.evaluate(test_dataset, verbose=0, batch_size=10)\n",
        "print(f'Test Accuracy: {round(test_accuracy, 4)}')\n",
        "print(f'Test Mean Intersection over Union: {round(test_mean_iou, 4)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jNjpbWmGwbR9",
      "metadata": {
        "id": "jNjpbWmGwbR9"
      },
      "outputs": [],
      "source": [
        "def plot_triptychs(dataset, model, num_samples=1):\n",
        "    \"\"\"\n",
        "    Plot triptychs (original image, true mask, predicted mask) for samples from a tf.data.Dataset\n",
        "\n",
        "    Parameters:\n",
        "    dataset: tf.data.Dataset - The dataset containing image-label pairs\n",
        "    model: tf.keras.Model - The trained model to generate predictions\n",
        "    num_samples: int - Number of samples to plot\n",
        "    \"\"\"\n",
        "    # Take samples from the dataset\n",
        "    samples = dataset.take(num_samples)\n",
        "\n",
        "    for images, labels in samples:\n",
        "        # If we have a batch, take the first example\n",
        "        if len(images.shape) == 4:  # Batch of images\n",
        "            images = images[0:1]\n",
        "            labels = labels[0:1]\n",
        "\n",
        "        # Generate predictions\n",
        "        pred = model.predict(images, verbose=0)\n",
        "        pred = tf.math.argmax(pred, axis=-1)\n",
        "\n",
        "        # Create colormap based on number of classes in labels\n",
        "        labels_np = labels.numpy()\n",
        "        num_classes = len(np.unique(labels_np))\n",
        "        colormap = create_segmentation_colormap(num_classes)\n",
        "\n",
        "        # Create figure with subplots\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(20, 4))\n",
        "\n",
        "        # Plot original image\n",
        "        axes[0].set_title(\"Original Image\")\n",
        "        axes[0].imshow(images[0])\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Plot original mask\n",
        "        axes[1].set_title(\"Original Mask\")\n",
        "        colored_label = apply_colormap(labels[0], colormap)\n",
        "        axes[1].imshow(colored_label)\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        # Plot predicted mask\n",
        "        axes[2].set_title(\"Predicted Mask\")\n",
        "        colored_pred = apply_colormap(pred[0], colormap)\n",
        "        axes[2].imshow(colored_pred)\n",
        "        axes[2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "# Example usage:\n",
        "# Plot three random samples\n",
        "plot_triptychs(test_dataset, model, num_samples=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "SOjzoij4Hm13",
      "metadata": {
        "id": "SOjzoij4Hm13"
      },
      "source": [
        "#  \n",
        "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n",
        "___\n",
        "Credits: Eugenio Lomurno üìß eugenio.lomurno@polimi.it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "   Copyright 2024 Eugenio Lomurno\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}