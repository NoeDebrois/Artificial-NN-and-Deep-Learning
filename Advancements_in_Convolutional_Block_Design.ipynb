{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoeDebrois/Artificial-NN-and-Deep-Learning/blob/main/Advancements_in_Convolutional_Block_Design.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRyyx0cfzGF9"
      },
      "source": [
        "# Artificial Neural Networks and Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "## Lecture 4a: Advancements in Convolutional Block Design\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ruszte0iwJ-i5VgTCApvJXz7yXWgnZzi\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdD_8Vyswkwf"
      },
      "source": [
        "## ‚öôÔ∏è Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_S1JfaW8bIN"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Import TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "\n",
        "# Set seed for TensorFlow\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Reduce TensorFlow verbosity\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Print TensorFlow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Import other libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configure plot display settings\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output dimensions\n",
        "input_shape = (64, 64, 3)\n",
        "output_shape = 10\n",
        "\n",
        "# Initialise configuration for convolutional layers\n",
        "stack = 1\n",
        "filters = 32\n",
        "kernel_size = 3"
      ],
      "metadata": {
        "id": "nLrhmuHmrxYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **First Convolutional Neural Network Block (AlexNet, 2012)**\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*bD_DMBtKwveuzIkQTwjKQQ.png\" width=\"800\"/>\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   First successful deep CNN for ImageNet\n",
        "*   Introduced ReLU to combat vanishing gradient\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   Conv -> ReLU -> MaxPool sequence\n",
        "*   Multiple layers stacked sequentially\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Started the \"deep learning revolution\"\n",
        "*   Established basic CNN design patterns\n",
        "\n",
        "**üìú Paper:** [\"ImageNet Classification with Deep Convolutional Neural Networks\", Krizhevsky et al.](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "u2arNe9atvaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_cnn_block(x, filters, kernel_size=3, padding='same',\n",
        "                    downsample=True, activation='relu', stack=2, name='basic'):\n",
        "    # Define a basic CNN block with Conv -> ReLU -> MaxPool pattern\n",
        "    for i in range(stack):\n",
        "        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv_{i}')(x)\n",
        "        x = tfkl.Activation(activation, name=f'{name}_act_{i}')(x)\n",
        "\n",
        "    # Add MaxPooling layer if downsample is True\n",
        "    if downsample:\n",
        "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# Add the CNN block to the model\n",
        "x = basic_cnn_block(x=input_layer, filters=filters, kernel_size=kernel_size, downsample=True, stack=stack, name='block0')\n",
        "\n",
        "# Flatten the output and add a dense layer\n",
        "x = tfkl.Flatten(name='flatten')(x)\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "\n",
        "# Apply softmax activation for output layer\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Create and compile the model\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot architecture\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "aSb4owGstTcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **Global Average Pooling (NiN, 2013)**\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/363231491/figure/fig5/AS:11431281179419529@1691187457237/Illustration-of-global-average-pooling-GAP.png\" width=\"800\"/>\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   Replaced Flatten and Dense layers\n",
        "*   Enforced correspondence between feature maps and categories\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   Global spatial average of each feature map\n",
        "*   Direct feature-to-category mapping\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Dramatic parameter reduction\n",
        "*   Better generalization with fewer parameters\n",
        "\n",
        "**üìú Paper:** [\"Network In Network\", Lin et al.](https://arxiv.org/pdf/1312.4400)\n",
        "\n"
      ],
      "metadata": {
        "id": "RkqPKmkQra2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# Add the basic CNN block to process the input\n",
        "x = basic_cnn_block(x=input_layer, filters=filters, kernel_size=kernel_size, downsample=True, stack=stack, name='block0')\n",
        "\n",
        "# Apply global average pooling to reduce spatial dimensions\n",
        "x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "\n",
        "# Add a dense layer for final output processing\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "\n",
        "# Apply softmax activation for output layer\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Create and compile the model\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot architecture\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "cx3Mww4hqtd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **Inception Block (GoogLeNet, 2014)**\n",
        "\n",
        "<img src=\"https://ar5iv.labs.arxiv.org/html/1707.07128/assets/googlenetInception.png\" width=\"800\"/>\n",
        "\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   Multi-scale feature processing\n",
        "*   Winner of ILSVRC 2014\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   Parallel paths with different kernels\n",
        "*   1x1 bottleneck for efficiency\n",
        "*   Feature concatenation\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Established multi-path processing\n",
        "*   Introduced 1x1 bottleneck concept\n",
        "\n",
        "**üìú Paper:** [\"Going deeper with convolutions\", Szegedy et al.](https://arxiv.org/pdf/1409.4842)"
      ],
      "metadata": {
        "id": "_Cl1WzXxuOLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inception_block(x, filters, kernel_size=3, padding='same',\n",
        "                    downsample=True, activation='relu', stack=2, name='inception'):\n",
        "    # Define the original Inception block (2014) structure without Batch Normalisation\n",
        "    for s in range(stack):\n",
        "        # 1x1 convolutional path\n",
        "        conv1 = tfkl.Conv2D(filters // 4, 1, padding=padding, name=f'{name}_conv1_{s}')(x)\n",
        "        conv1 = tfkl.Activation(activation)(conv1)\n",
        "\n",
        "        # 3x3 convolutional path with initial reduction\n",
        "        conv3_reduce = tfkl.Conv2D(filters // 8, 1, padding=padding)(x)\n",
        "        conv3_reduce = tfkl.Activation(activation)(conv3_reduce)\n",
        "        conv3 = tfkl.Conv2D(filters // 4, 3, padding=padding, name=f'{name}_conv3_{s}')(conv3_reduce)\n",
        "        conv3 = tfkl.Activation(activation)(conv3)\n",
        "\n",
        "        # 5x5 convolutional path with initial reduction\n",
        "        conv5_reduce = tfkl.Conv2D(filters // 12, 1, padding=padding)(x)\n",
        "        conv5_reduce = tfkl.Activation(activation)(conv5_reduce)\n",
        "        conv5 = tfkl.Conv2D(filters // 4, 5, padding=padding, name=f'{name}_conv5_{s}')(conv5_reduce)\n",
        "        conv5 = tfkl.Activation(activation)(conv5)\n",
        "\n",
        "        # Pooling path with projection\n",
        "        pool = tfkl.MaxPooling2D(3, strides=1, padding=padding)(x)\n",
        "        pool_proj = tfkl.Conv2D(filters // 4, 1, padding=padding)(pool)\n",
        "        pool_proj = tfkl.Activation(activation)(pool_proj)\n",
        "\n",
        "        # Concatenate paths\n",
        "        x = tfkl.Concatenate(name=f'{name}_concat_{s}')([conv1, conv3, conv5, pool_proj])\n",
        "\n",
        "    # Apply downsampling if specified\n",
        "    if downsample:\n",
        "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# Add the Inception block to process the input\n",
        "x = inception_block(x=input_layer, filters=filters, kernel_size=kernel_size, downsample=True, stack=stack, name='block0')\n",
        "\n",
        "# Apply global average pooling to reduce spatial dimensions\n",
        "x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "\n",
        "# Add a dense layer for final output processing\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "\n",
        "# Apply softmax activation for output layer\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Create and compile the model\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot architecture\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "hafbI5_Rqta_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **Batch Normalization (Inception Block with BN, 2015)**\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:898/0*pSSzicm1IH4hXOHc.png\" width=\"800\"/>\n",
        "\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   Normalized activations in each layer\n",
        "*   Reduced internal covariate shift\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   Normalize: $\\hat{x} = \\frac{x-\\mu_B}{\\sqrt{\\sigma^2_B+\\epsilon}}$\n",
        "*   Scale and shift: $y = \\gamma\\hat{x} + \\beta$\n",
        "*   Placed before activation\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Enabled much faster training\n",
        "*   Reduced sensitivity to initialization\n",
        "*   Became standard in modern networks\n",
        "\n",
        "**üìú Paper:** [\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\", Ioffe and Szegedy](https://arxiv.org/pdf/1502.03167)"
      ],
      "metadata": {
        "id": "IpTP8L0z2O9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Inception block with BN and with multiple convolution paths and optional downsampling\n",
        "def inception_block_bn(x, filters, kernel_size=3, padding='same',\n",
        "                       downsample=True, activation='relu', stack=2, name='inception'):\n",
        "    # Loop through specified stack layers for multiple inception paths\n",
        "    for s in range(stack):\n",
        "        # 1x1 convolution path with batch normalization and activation\n",
        "        conv1 = tfkl.Conv2D(filters // 4, 1, padding=padding, name=f'{name}_conv1_{s}')(x)\n",
        "        conv1 = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(conv1)\n",
        "        conv1 = tfkl.Activation(activation, name=f'{name}_act1_{s}')(conv1)\n",
        "\n",
        "        # 3x3 convolution path with initial reduction layer\n",
        "        conv3_reduce = tfkl.Conv2D(filters // 8, 1, padding=padding, name=f'{name}_conv3_reduce_{s}')(x)\n",
        "        conv3_reduce = tfkl.BatchNormalization(name=f'{name}_bn3_reduce_{s}')(conv3_reduce)\n",
        "        conv3_reduce = tfkl.Activation(activation, name=f'{name}_act3_reduce_{s}')(conv3_reduce)\n",
        "        conv3 = tfkl.Conv2D(filters // 4, 3, padding=padding, name=f'{name}_conv3_{s}')(conv3_reduce)\n",
        "        conv3 = tfkl.BatchNormalization(name=f'{name}_bn3_{s}')(conv3)\n",
        "        conv3 = tfkl.Activation(activation, name=f'{name}_act3_{s}')(conv3)\n",
        "\n",
        "        # 5x5 convolution path with initial reduction layer\n",
        "        conv5_reduce = tfkl.Conv2D(filters // 12, 1, padding=padding, name=f'{name}_conv5_reduce_{s}')(x)\n",
        "        conv5_reduce = tfkl.BatchNormalization(name=f'{name}_bn5_reduce_{s}')(conv5_reduce)\n",
        "        conv5_reduce = tfkl.Activation(activation, name=f'{name}_act5_reduce_{s}')(conv5_reduce)\n",
        "        conv5 = tfkl.Conv2D(filters // 4, 5, padding=padding, name=f'{name}_conv5_{s}')(conv5_reduce)\n",
        "        conv5 = tfkl.BatchNormalization(name=f'{name}_bn5_{s}')(conv5)\n",
        "        conv5 = tfkl.Activation(activation, name=f'{name}_act5_{s}')(conv5)\n",
        "\n",
        "        # Pooling path with projection for spatial dimensionality reduction\n",
        "        pool = tfkl.MaxPooling2D(3, strides=1, padding=padding, name=f'{name}_pooling_{s}')(x)\n",
        "        pool_proj = tfkl.Conv2D(filters // 4, 1, padding=padding, name=f'{name}_pool_proj_{s}')(pool)\n",
        "        pool_proj = tfkl.BatchNormalization(name=f'{name}_bn_pool_proj_{s}')(pool_proj)\n",
        "        pool_proj = tfkl.Activation(activation, name=f'{name}_act_pool_proj_{s}')(pool_proj)\n",
        "\n",
        "        # Concatenate all paths to form the final block output\n",
        "        x = tfkl.Concatenate(name=f'{name}_concat_{s}')([conv1, conv3, conv5, pool_proj])\n",
        "\n",
        "    # Apply downsampling if specified\n",
        "    if downsample:\n",
        "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
        "    return x\n",
        "\n",
        "# Define the input layer for the model\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# Apply the Inception block to process the input layer\n",
        "x = inception_block_bn(x=input_layer, filters=filters, kernel_size=kernel_size, downsample=True, stack=stack, name='block0')\n",
        "\n",
        "# Apply global average pooling to reduce the spatial dimensions\n",
        "x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "\n",
        "# Add a dense layer for classification output processing\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "\n",
        "# Apply softmax activation to generate final output probabilities\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Create and compile the model architecture\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot model architecture\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "H1lCnHdi2PG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **Residual Block (ResNet, 2015)**\n",
        "\n",
        "<img src=\"https://production-media.paperswithcode.com/methods/resnet-e1548261477164.png\" width=\"800\"/>\n",
        "\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   Enabled 1000+ layer networks\n",
        "*   Winner of ILSVRC 2015\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   Skip connection: F(x) + x\n",
        "*   Two conv layers with BN and ReLU\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Solved deep network degradation\n",
        "*   Revolutionized network design\n",
        "\n",
        "**üìú Paper:** [\"Deep Residual Learning for Image Recognition\", He et al.](https://arxiv.org/pdf/1512.03385)"
      ],
      "metadata": {
        "id": "P1bSqyAL0RzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Residual block with configurable parameters\n",
        "def residual_block(x, filters, kernel_size=3, padding='same',\n",
        "                   downsample=True, activation='relu', stack=2, name='residual'):\n",
        "\n",
        "    for s in range(stack):\n",
        "        # Save input for skip connection\n",
        "        skip = x\n",
        "\n",
        "        # First convolutional block with Batch Normalisation and activation\n",
        "        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv1_{s}')(x)\n",
        "        x = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(x)\n",
        "        x = tfkl.Activation(activation, name=f'{name}_act1_{s}')(x)\n",
        "\n",
        "        # Second convolutional block\n",
        "        x = tfkl.Conv2D(filters, kernel_size, padding=padding, name=f'{name}_conv2_{s}')(x)\n",
        "        x = tfkl.BatchNormalization(name=f'{name}_bn2_{s}')(x)\n",
        "\n",
        "        # Adjust skip connection dimension if needed\n",
        "        if skip.shape[-1] != filters:\n",
        "            skip = tfkl.Conv2D(filters, 1, padding=padding, name=f'{name}_proj_{s}')(skip)\n",
        "            skip = tfkl.BatchNormalization(name=f'{name}_proj_bn_{s}')(skip)\n",
        "\n",
        "        # Add skip connection and apply activation\n",
        "        x = tfkl.Add(name=f'{name}_add_{s}')([x, skip])\n",
        "        x = tfkl.Activation(activation, name=f'{name}_act2_{s}')(x)\n",
        "\n",
        "    # Optional downsampling\n",
        "    if downsample:\n",
        "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Define the input layer and initial convolutional block\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "x = tfkl.Conv2D(filters=filters, kernel_size=kernel_size, padding='same', name='conv0')(input_layer)\n",
        "x = tfkl.BatchNormalization(name='bn0')(x)\n",
        "x = tfkl.Activation('relu', name='act0')(x)\n",
        "\n",
        "# Apply residual block and subsequent global pooling and output layer\n",
        "x = residual_block(x=x, filters=filters, kernel_size=kernel_size, downsample=False, stack=stack, name='block0')\n",
        "x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "-a4znc8WqtYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **Squeeze-and-Excitation Block (SENet, 2017)**\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*QK1TVTasgdRYpVC31CuPyA.png\" width=\"800\"/>\n",
        "\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   Channel \"attention\" mechanism\n",
        "*   Winner of ILSVRC 2017\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   Squeeze: global pooling\n",
        "*   Excitation: channel recalibration\n",
        "*   Feature rescaling\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Introduced \"attention\" in CNNs\n",
        "*   Minimal overhead, significant gain\n",
        "\n",
        "**üìú Paper:** [\"Squeeze-and-Excitation Networks\", Hu et al.](https://arxiv.org/pdf/1709.01507)"
      ],
      "metadata": {
        "id": "IfLhPch5-LPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SENet block with configurable parameters\n",
        "def senet_block(x, filters, kernel_size=3, padding='same',\n",
        "                downsample=True, activation='relu', stack=2, name='senet'):\n",
        "\n",
        "    for s in range(stack):\n",
        "        # Main convolutional path\n",
        "        x = tfkl.Conv2D(filters, kernel_size, padding=padding,\n",
        "                        use_bias=False, name=f'{name}_conv_{s}')(x)\n",
        "        x = tfkl.BatchNormalization(name=f'{name}_bn_{s}')(x)\n",
        "        x = tfkl.Activation(activation, name=f'{name}_act_{s}')(x)\n",
        "\n",
        "        # Squeeze-and-Excitation (SE) module\n",
        "        channels = x.shape[-1]\n",
        "\n",
        "        # Squeeze step\n",
        "        se = tfkl.GlobalAveragePooling2D(name=f'{name}_squeeze_{s}')(x)\n",
        "\n",
        "        # Excitation step\n",
        "        se = tfkl.Dense(channels // 16, activation=activation, name=f'{name}_dense1_{s}')(se)\n",
        "        se = tfkl.Dense(channels, activation='sigmoid', name=f'{name}_dense2_{s}')(se)\n",
        "\n",
        "        # Scaling of the output with SE activation\n",
        "        se = tfkl.Reshape((1, 1, channels))(se)\n",
        "        x = tfkl.Multiply(name=f'{name}_scale_{s}')([x, se])\n",
        "\n",
        "    # Optional downsampling\n",
        "    if downsample:\n",
        "        x = tfkl.MaxPooling2D(2, name=f'{name}_pool')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Define the input layer and apply SENet block\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "x = senet_block(x=input_layer, filters=filters, kernel_size=kernel_size, downsample=False, stack=stack, name='block0')\n",
        "\n",
        "# Global Average Pooling and fully connected output layer\n",
        "x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "uproKfNFqtVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è **Inverted Residual Bottleneck with SE (MobileNetV3, 2019)**\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/378806327/figure/fig5/AS:11431281232045939@1711587010842/MobileNetV3-network-structure.jpg\" width=\"600\"/>\n",
        "\n",
        "\n",
        "---\n",
        "**Key Features and Achievements**\n",
        "\n",
        "\n",
        "*   Pioneered platform-aware Neural Architecture Search (NAS)\n",
        "*   Introduced hardware-aware network design\n",
        "*   Combined manual design with automated search\n",
        "*   Optimized for mobile inference latency\n",
        "\n",
        "**Key building block:**\n",
        "\n",
        "*   \"Enhanced\" Inverted Residual Block (Expansion ratio tuned per block, SE module redesigned for efficiency, Hard-Swish activation function(h-swish))\n",
        "*   Efficient last stage design (Reduced channels in first layer, moved SE to cheaper layers, platform-aware operator selection)\n",
        "\n",
        "**Impact:**\n",
        "\n",
        "*   Set new SOTA for mobile networks\n",
        "*   Demonstrated successful NAS and human design fusion\n",
        "*   Showed importance of hardware-aware architecture design\n",
        "*   Influenced automated architecture search methods\n",
        "\n",
        "**üìú Paper:** [\"Searching for MobileNetV3\", Howard et al.](https://arxiv.org/pdf/1905.02244)\n",
        "\n",
        "---\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1EcBp60nEorTDLROT_1L4a4Mvw9kLdKqd\" width=\"300\"/>"
      ],
      "metadata": {
        "id": "xdKdd0GH__Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the MobileNetV3 block with configurable parameters\n",
        "def mobilenetv3_block(x, filters, kernel_size=3, padding='same',\n",
        "                      downsample=True, activation='relu', stack=1, name='mobilev3'):\n",
        "\n",
        "    # Define h-swish activation function\n",
        "    def h_swish(x):\n",
        "        return x * tf.nn.relu6(x + 3.0) / 6.0\n",
        "\n",
        "    # Select activation function\n",
        "    activation_fn = tf.nn.relu if activation == 'relu' else h_swish\n",
        "\n",
        "    for s in range(stack):\n",
        "        input_channels = x.shape[-1]\n",
        "        residual = x\n",
        "\n",
        "        # Set expansion factor based on channel dimensions\n",
        "        expansion_factor = 1 if input_channels == filters else 6\n",
        "        expanded_channels = input_channels * expansion_factor\n",
        "\n",
        "        # Expansion phase\n",
        "        if expansion_factor != 1:\n",
        "            x = tfkl.Conv2D(expanded_channels, 1, padding=padding, use_bias=False, name=f'{name}_expand_{s}')(x)\n",
        "            x = tfkl.BatchNormalization(name=f'{name}_bn1_{s}')(x)\n",
        "            x = tfkl.Activation(activation_fn, name=f'{name}_act1_{s}')(x)\n",
        "\n",
        "        # Depthwise convolution with optional downsampling\n",
        "        stride = 2 if (downsample and s == 0) else 1\n",
        "        x = tfkl.DepthwiseConv2D(kernel_size, strides=stride, padding=padding, use_bias=False, name=f'{name}_depthwise_{s}')(x)\n",
        "        x = tfkl.BatchNormalization(name=f'{name}_bn2_{s}')(x)\n",
        "        x = tfkl.Activation(activation_fn, name=f'{name}_act2_{s}')(x)\n",
        "\n",
        "        # Squeeze-and-Excitation module\n",
        "        se_channels = max(1, expanded_channels // 4)\n",
        "        se = tfkl.GlobalAveragePooling2D(name=f'{name}_se_pool_{s}')(x)\n",
        "        se = tfkl.Reshape((1, 1, expanded_channels))(se)\n",
        "        se = tfkl.Conv2D(se_channels, 1, activation='relu', name=f'{name}_se_reduce_{s}')(se)\n",
        "        se = tfkl.Conv2D(expanded_channels, 1, activation='hard_sigmoid', name=f'{name}_se_expand_{s}')(se)\n",
        "        x = tfkl.Multiply(name=f'{name}_se_excite_{s}')([x, se])\n",
        "\n",
        "        # Projection phase to desired filter dimension\n",
        "        x = tfkl.Conv2D(filters, 1, padding=padding, use_bias=False, name=f'{name}_project_{s}')(x)\n",
        "        x = tfkl.BatchNormalization(name=f'{name}_bn3_{s}')(x)\n",
        "\n",
        "        # Add skip connection if applicable\n",
        "        if stride == 1 and input_channels == filters:\n",
        "            x = tfkl.Add(name=f'{name}_add_{s}')([residual, x])\n",
        "\n",
        "    return x\n",
        "\n",
        "# Define the input layer and apply MobileNetV3 block\n",
        "input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "x = mobilenetv3_block(x=input_layer, filters=filters, kernel_size=kernel_size, downsample=False, name='block0')\n",
        "\n",
        "# Global Average Pooling and fully connected output layer\n",
        "x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "x = tfkl.Dense(output_shape, name='dense')(x)\n",
        "x = tfkl.Activation('softmax', name='softmax')(x)\n",
        "\n",
        "# Compile the model\n",
        "model = tfk.Model(inputs=input_layer, outputs=x, name='architecture')\n",
        "model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam())\n",
        "\n",
        "# Display model summary and plot\n",
        "model.summary(expand_nested=True, show_trainable=True)\n",
        "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
      ],
      "metadata": {
        "id": "mGI4vdIrqtSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4tWF6oUQFqH"
      },
      "source": [
        "#  \n",
        "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n",
        "___\n",
        "Credits: Eugenio Lomurno üìß eugenio.lomurno@polimi.it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "   Copyright 2024 Eugenio Lomurno\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "u2arNe9atvaZ",
        "RkqPKmkQra2A",
        "_Cl1WzXxuOLA",
        "IpTP8L0z2O9J",
        "P1bSqyAL0RzV",
        "IfLhPch5-LPC",
        "xdKdd0GH__Xt"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}