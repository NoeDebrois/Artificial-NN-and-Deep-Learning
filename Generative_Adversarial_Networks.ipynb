{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoeDebrois/Artificial-NN-and-Deep-Learning/blob/main/Generative_Adversarial_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yRomA3su_K8b",
      "metadata": {
        "id": "yRomA3su_K8b"
      },
      "source": [
        "# Artificial Neural Networks and Deep Learning\n",
        "\n",
        "---\n",
        "\n",
        "## Lecture 6b: Generative Adversarial Networks\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1dxxXvi8Bm3MEunIoRvIKdF_JI1o7YxC-\" width=\"500\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TlN1vUkSlKec",
      "metadata": {
        "id": "TlN1vUkSlKec"
      },
      "source": [
        "## üåê Connect Colab to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X9--McjQJeJ_",
      "metadata": {
        "id": "X9--McjQJeJ_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive/[2024-2025] AN2DL/Lecture 6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wif7zyIyJh0q",
      "metadata": {
        "id": "wif7zyIyJh0q"
      },
      "source": [
        "## ‚öôÔ∏è Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YAir-9fDjp32",
      "metadata": {
        "id": "YAir-9fDjp32"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "\n",
        "# Set environment variables before importing modules\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "# Import necessary modules\n",
        "import logging\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seeds for random number generators in NumPy and Python\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# Import TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tfk\n",
        "from tensorflow.keras import layers as tfkl\n",
        "\n",
        "# Set seed for TensorFlow\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "# Reduce TensorFlow verbosity\n",
        "tf.autograph.set_verbosity(0)\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "\n",
        "# Print TensorFlow version\n",
        "print(tf.__version__)\n",
        "\n",
        "# Import other libraries\n",
        "from PIL import Image\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "# Configure plot display settings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=1.4)\n",
        "sns.set_style('white')\n",
        "plt.rc('font', size=14)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Setup Hyperparameters"
      ],
      "metadata": {
        "id": "Nz0Bb3UQMthg"
      },
      "id": "Nz0Bb3UQMthg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hW5haIckBDvU",
      "metadata": {
        "id": "hW5haIckBDvU"
      },
      "outputs": [],
      "source": [
        "# Define training hyperparameters\n",
        "epochs = 50\n",
        "learning_rate = 5e-5\n",
        "batch_size = 64\n",
        "latent_dim = 64\n",
        "\n",
        "# Print current parameters\n",
        "print(f\"Parameters defined:\\n\"\n",
        "      f\"  epochs:        {epochs:>8}\\n\"\n",
        "      f\"  learning_rate: {learning_rate:>8.1e}\\n\"\n",
        "      f\"  batch_size:    {batch_size:>8}\\n\"\n",
        "      f\"  latent_dim:    {latent_dim:>8}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cAONSBpsJnvL",
      "metadata": {
        "id": "cAONSBpsJnvL"
      },
      "source": [
        "## ‚è≥ Load and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb98bed5",
      "metadata": {
        "id": "bb98bed5"
      },
      "outputs": [],
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "(X_train_val, y_train_val), (X_test, y_test) = tfk.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Add channel dimension to data\n",
        "X_train_val = X_train_val[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "# Resize images to 32x32\n",
        "X_train_val = tfk.preprocessing.image.smart_resize(X_train_val, (32, 32))\n",
        "X_test = tfk.preprocessing.image.smart_resize(X_test, (32, 32))\n",
        "\n",
        "# Normalise pixel values to range [-1, 1]\n",
        "X_train_val = (X_train_val.astype('float32') - 127.5) / 127.5\n",
        "X_test = (X_test.astype('float32') - 127.5) / 127.5\n",
        "\n",
        "# Print shapes of training and test data\n",
        "print(\"Training data shape:\", X_train_val.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n",
        "\n",
        "# Define class names for the dataset\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Concatenate training and test data\n",
        "X = np.concatenate([X_train_val, X_test], axis=0)\n",
        "y = np.concatenate([y_train_val, y_test], axis=0).astype('int32')\n",
        "\n",
        "# Print shapes of concatenated data\n",
        "print(f\"Combined data shape: X={X.shape}, y={y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecO2zUQuATis",
      "metadata": {
        "id": "ecO2zUQuATis"
      },
      "outputs": [],
      "source": [
        "# Inspect sample images from the training data\n",
        "fig, axes = plt.subplots(1, 10, figsize=(20, 10))\n",
        "\n",
        "# Loop through the first 10 images\n",
        "for i in range(10):\n",
        "    ax = axes[i % 10]\n",
        "\n",
        "    # Display image and its corresponding label\n",
        "    ax.imshow(np.squeeze(X_train_val[i]), cmap='gray')\n",
        "    ax.set_title(class_names[y_train_val[i]], pad=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "# Adjust layout for better visualisation\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68a2a2d6",
      "metadata": {
        "id": "68a2a2d6"
      },
      "outputs": [],
      "source": [
        "# Print shape and statistical properties of the dataset\n",
        "print('Data shape:', X.shape)\n",
        "print('Data min: {:0.2f}\\nData max: {:0.2f}\\nData mean: {:0.2f}\\nData std: {:0.2f}'.format(\n",
        "    X.min(), X.max(), X.mean(), X.std()))\n",
        "\n",
        "# Define input shape for the model\n",
        "input_shape = X.shape[1:]\n",
        "\n",
        "# Print input shape\n",
        "print(f\"Input shape: {input_shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d9ec70-74ed-4d67-9b53-631da7e6d218",
      "metadata": {
        "id": "47d9ec70-74ed-4d67-9b53-631da7e6d218"
      },
      "source": [
        "## üõ†Ô∏è Generative Adversarial Network (GAN)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=19PsuOIjonMAvecVBeEto0sTea2EviNgW\" width=\"700\"/>\n",
        "\n",
        "**Variables and Parameters**\n",
        "\n",
        "$D$: Discriminator network (outputs probability between 0 and 1)\n",
        "\n",
        "$G$: Generator network (creates synthetic samples)\n",
        "\n",
        "$x$: Input data samples\n",
        "\n",
        "$p_r(x)$: Probability distribution of real data samples\n",
        "\n",
        "$p_g(x)$: Probability distribution of generated (fake) samples\n",
        "\n",
        "$L(G,D)$: Loss function to be optimized\n",
        "\n",
        "$\\mathbb{E}$: Expected value operator\n",
        "\n",
        "**Formula**\n",
        "\n",
        "$$\n",
        "\\min_{G} \\max_{D} L(G,D) = \\mathbb{E}_{x \\sim p_r(x)}[\\log(D(x))] + \\mathbb{E}_{x \\sim p_g(x)}[\\log(1-D(x))]\n",
        "$$\n",
        "\n",
        "**Description**\n",
        "\n",
        "This formula represents the core objective function of a Generative Adversarial Network (GAN). It establishes a minimax game between two neural networks:\n",
        "\n",
        "1. The discriminator (D) aims to maximize the function by correctly classifying real and fake samples\n",
        "2. The generator (G) aims to minimize the function by creating samples that fool the discriminator\n",
        "3. The $\\log(D(x))$ term rewards the discriminator for correctly identifying real samples\n",
        "4. The $\\log(1-D(x))$ term rewards the discriminator for correctly identifying fake samples\n",
        "\n",
        "Theoretically, at equilibrium, this adversarial process should result in the generator producing samples that are indistinguishable from real data, while the discriminator's predictions converge to 0.5 for both real and generated samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14d2760",
      "metadata": {
        "id": "a14d2760"
      },
      "outputs": [],
      "source": [
        "# Define a function to build the discriminator model\n",
        "def get_discriminator(input_shape, seed=seed):\n",
        "    # Set random seed for reproducibility\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "    # First convolutional block\n",
        "    x = tfkl.Conv2D(32, 4, padding='same', strides=2, name='conv1')(input_layer)\n",
        "    x = tfkl.LayerNormalization(name='ln1')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n",
        "\n",
        "    # Second convolutional block\n",
        "    x = tfkl.Conv2D(64, 4, padding='same', strides=2, name='conv2')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln2')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n",
        "\n",
        "    # Third convolutional block\n",
        "    x = tfkl.Conv2D(128, 4, padding='same', strides=2, name='conv3')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln3')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n",
        "\n",
        "    # Global average pooling and dense layers for classification\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    x = tfkl.Dense(256, name='dense1')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln4')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation4')(x)\n",
        "    output_layer = tfkl.Dense(1, name='dense_out')(x)\n",
        "\n",
        "    # Return the discriminator model\n",
        "    return tf.keras.Model(inputs=input_layer, outputs=output_layer, name='discriminator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TbtOimVjA9dg",
      "metadata": {
        "id": "TbtOimVjA9dg"
      },
      "outputs": [],
      "source": [
        "# Instantiate the discriminator model\n",
        "discriminator = get_discriminator(input_shape)\n",
        "\n",
        "# Print a detailed summary of the discriminator\n",
        "discriminator.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "# Generate and display a graphical representation of the discriminator architecture\n",
        "tf.keras.utils.plot_model(\n",
        "    discriminator,\n",
        "    show_trainable=True,\n",
        "    expand_nested=True,\n",
        "    dpi=70\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b691b597",
      "metadata": {
        "id": "b691b597"
      },
      "outputs": [],
      "source": [
        "# Define a function to build the generator model\n",
        "def get_generator(input_shape, seed=seed):\n",
        "    # Set random seed for reproducibility\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Define input layer\n",
        "    input_layer = tfkl.Input(shape=(input_shape,), name='Input')\n",
        "\n",
        "    # Dense layer to expand input to a 4x4x64 feature map\n",
        "    x = tfkl.Dense(4 * 4 * 64, use_bias=False, name='dense0')(input_layer)\n",
        "    x = tfkl.LayerNormalization(name='ln0')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation0')(x)\n",
        "    x = tfkl.Reshape((4, 4, 64))(x)\n",
        "\n",
        "    # First upsampling block\n",
        "    x = tfkl.UpSampling2D(name='upsampling1')(x)\n",
        "    x = tfkl.Conv2D(64, 3, padding='same', use_bias=False, name='conv1')(x)\n",
        "    x = tfkl.LayerNormalization(name='bn1')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n",
        "\n",
        "    # Second upsampling block\n",
        "    x = tfkl.UpSampling2D(name='upsampling2')(x)\n",
        "    x = tfkl.Conv2D(128, 3, padding='same', use_bias=False, name='conv2')(x)\n",
        "    x = tfkl.LayerNormalization(name='bn2')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n",
        "\n",
        "    # Third upsampling block\n",
        "    x = tfkl.UpSampling2D(name='upsampling3')(x)\n",
        "    x = tfkl.Conv2D(256, 3, padding='same', use_bias=False, name='conv3')(x)\n",
        "    x = tfkl.LayerNormalization(name='bn3')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n",
        "\n",
        "    # Output layer with a single channel and tanh activation\n",
        "    x = tfkl.Conv2D(1, 3, padding='same', use_bias=False, name='conv_out')(x)\n",
        "    output_layer = tfkl.Activation('tanh', name='activation_out')(x)\n",
        "\n",
        "    # Return the generator model\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='generator')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ivP-C6KZBPiM",
      "metadata": {
        "id": "ivP-C6KZBPiM"
      },
      "outputs": [],
      "source": [
        "# Obtain a generator model based on the specified latent dimension\n",
        "generator = get_generator(latent_dim)\n",
        "\n",
        "# Print a detailed summary of the generator, including expanded nested layers and trainable parameters\n",
        "generator.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "# Generate and display a graphical representation of the generator architecture\n",
        "tf.keras.utils.plot_model(\n",
        "    generator,\n",
        "    show_trainable=True,\n",
        "    expand_nested=True,\n",
        "    dpi=70\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ac0e2e3",
      "metadata": {
        "id": "9ac0e2e3"
      },
      "outputs": [],
      "source": [
        "# Define a GAN class inheriting from tf.keras.Model\n",
        "class GAN(tfk.Model):\n",
        "\n",
        "    # Initialise the GAN with a discriminator, generator, latent dimension, and discriminator update frequency\n",
        "    def __init__(self, discriminator, generator, latent_dim, n_discriminator_updates=3):\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.n_discriminator_updates = n_discriminator_updates\n",
        "\n",
        "        # Initialise loss trackers for discriminator and generator\n",
        "        self.d_loss_tracker = tfk.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = tfk.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    # Compile the GAN with optimisers and an optional loss function\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn=None):\n",
        "        super(GAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn or tfk.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    # Define GAN metrics\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_tracker, self.g_loss_tracker]\n",
        "\n",
        "    # Compute generator loss\n",
        "    def _generator_loss(self, fake_output):\n",
        "        return self.loss_fn(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    # Compute discriminator loss\n",
        "    def _discriminator_loss(self, real_output, fake_output):\n",
        "        real_loss = self.loss_fn(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = self.loss_fn(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    # Define the training step\n",
        "    @tf.function\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        # Train discriminator multiple times\n",
        "        d_loss = 0\n",
        "        for _ in range(self.n_discriminator_updates):\n",
        "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                generated_images = self.generator(random_latent_vectors, training=True)\n",
        "                real_output = self.discriminator(real_images, training=True)\n",
        "                fake_output = self.discriminator(generated_images, training=True)\n",
        "                current_d_loss = self._discriminator_loss(real_output, fake_output)\n",
        "\n",
        "            # Update discriminator weights\n",
        "            grads = tape.gradient(current_d_loss, self.discriminator.trainable_weights)\n",
        "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "            d_loss += current_d_loss / self.n_discriminator_updates\n",
        "\n",
        "        # Generate random latent vectors\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Train generator\n",
        "        with tf.GradientTape() as tape:\n",
        "            generated_images = self.generator(random_latent_vectors, training=True)\n",
        "            fake_output = self.discriminator(generated_images, training=False)\n",
        "            g_loss = self._generator_loss(fake_output)\n",
        "\n",
        "        # Update generator weights\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update loss trackers\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "\n",
        "        # Return loss metrics\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36a0b459",
      "metadata": {
        "id": "36a0b459"
      },
      "outputs": [],
      "source": [
        "# Define a GANMonitor callback to visualise generated images during training\n",
        "class GANMonitor(tfk.callbacks.Callback):\n",
        "\n",
        "    # Initialise the callback with the number of images, latent dimension, name, and colour mode\n",
        "    def __init__(self, num_img=10, latent_dim=latent_dim, name='', gray=False):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "        self.name = name\n",
        "        self.gray = gray\n",
        "\n",
        "    # Generate and display images at the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Set random seed for reproducibility\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "        # Ensure output directory exists\n",
        "        os.makedirs(self.name + 'temp', exist_ok=True)\n",
        "\n",
        "        # Generate latent vectors and images\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors).numpy()\n",
        "        generated_images = generated_images * 0.5 + 0.5  # Rescale pixel values\n",
        "\n",
        "        # Plot generated images\n",
        "        fig, axes = plt.subplots(1, self.num_img, figsize=(20, self.num_img))\n",
        "        for i in range(self.num_img):\n",
        "            img = tfk.preprocessing.image.array_to_img(generated_images[i])\n",
        "            ax = axes[i % self.num_img]\n",
        "            if self.gray:\n",
        "                ax.imshow(np.squeeze(img), cmap='gray')\n",
        "            else:\n",
        "                ax.imshow(np.squeeze(img))\n",
        "            ax.axis('off')\n",
        "\n",
        "        # Adjust layout and display the plot\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64472b8b",
      "metadata": {
        "id": "64472b8b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Create an instance of the GAN model with specified discriminator, generator, and latent dimension\n",
        "gan = GAN(\n",
        "    discriminator=get_discriminator(input_shape),\n",
        "    generator=get_generator(latent_dim),\n",
        "    latent_dim=latent_dim\n",
        ")\n",
        "\n",
        "# Compile the GAN model with Adam optimisers for both discriminator and generator\n",
        "gan.compile(\n",
        "    d_optimizer=tfk.optimizers.AdamW(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999),\n",
        "    g_optimizer=tfk.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19242f0c",
      "metadata": {
        "id": "19242f0c"
      },
      "outputs": [],
      "source": [
        "# Generate and display sample images from a model\n",
        "def sample(model, num_img, latent_dim, fixed=True, gray=False):\n",
        "    # Optionally set a fixed random seed for reproducibility\n",
        "    if fixed:\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "    # Generate random latent vectors and produce images\n",
        "    z = tf.random.normal(shape=(num_img, latent_dim))\n",
        "    generated_images = model(z).numpy()\n",
        "    generated_images = generated_images * 0.5 + 0.5  # Rescale pixel values\n",
        "\n",
        "    # Plot the generated images\n",
        "    fig, axes = plt.subplots(1, num_img, figsize=(20, num_img))\n",
        "    for i in range(num_img):\n",
        "        img = tfk.preprocessing.image.array_to_img(generated_images[i])\n",
        "        ax = axes[i % num_img]\n",
        "        if gray:\n",
        "            ax.imshow(np.squeeze(img), cmap='gray')\n",
        "        else:\n",
        "            ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Adjust layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate a dataset of images from a model\n",
        "def generate_dataset(model, num_img, latent_dim, fixed=True):\n",
        "    # Optionally set a fixed random seed for reproducibility\n",
        "    if fixed:\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "    # Generate random latent vectors and produce images\n",
        "    z = tf.random.normal(shape=(num_img, latent_dim))\n",
        "    generated_images = model(z).numpy()\n",
        "    generated_images = generated_images * 0.5 + 0.5  # Rescale pixel values\n",
        "\n",
        "    # Return the generated dataset\n",
        "    return generated_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f35c6a",
      "metadata": {
        "id": "c5f35c6a"
      },
      "outputs": [],
      "source": [
        "# Generate and display 10 sample images from the GAN's generator\n",
        "# Disable fixed random seed and display images in grayscale\n",
        "sample(gan.generator, 10, latent_dim, fixed=False, gray=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09d49dff",
      "metadata": {
        "id": "09d49dff"
      },
      "outputs": [],
      "source": [
        "# Train the GAN model on the dataset with specified parameters\n",
        "history = gan.fit(\n",
        "    X,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[GANMonitor(name='fashionmnist_gan', gray=True)],\n",
        "    verbose=2\n",
        ").history\n",
        "\n",
        "# Save the trained generator model\n",
        "gan.generator.save('fashionmnist_gan.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21eec0e0",
      "metadata": {
        "id": "21eec0e0"
      },
      "outputs": [],
      "source": [
        "# Plot the discriminator loss during training\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(history['d_loss'], label='Discriminator loss', alpha=0.8, linewidth=3)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Plot the generator loss during training\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(history['g_loss'], label='Generator loss', alpha=0.8, linewidth=3)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üïπÔ∏è Use the Model - Make Inference"
      ],
      "metadata": {
        "id": "O0up6m66QoqL"
      },
      "id": "O0up6m66QoqL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da1d4ca9-ac88-4b6a-8ab1-71d77ff2ef65",
      "metadata": {
        "id": "da1d4ca9-ac88-4b6a-8ab1-71d77ff2ef65"
      },
      "outputs": [],
      "source": [
        "# Load the saved GAN generator model\n",
        "gan_generator = tfk.models.load_model('fashionmnist_gan.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eebf7ad9",
      "metadata": {
        "id": "eebf7ad9"
      },
      "outputs": [],
      "source": [
        "# Generate and display 10 grayscale sample images using the loaded GAN generator\n",
        "# Disable fixed random seed for both invocations\n",
        "sample(gan_generator, 10, latent_dim, fixed=False, gray=True)\n",
        "sample(gan_generator, 10, latent_dim, fixed=False, gray=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8749426-d1cc-4edf-b4bc-1c9c079737ee",
      "metadata": {
        "id": "c8749426-d1cc-4edf-b4bc-1c9c079737ee"
      },
      "source": [
        "## üõ†Ô∏è Conditional Generative Adversarial Network (cGAN)\n",
        "\n",
        "**Variables and Parameters**\n",
        "\n",
        "$D$: Discriminator network (outputs probability between 0 and 1)  \n",
        "$G$: Generator network (creates synthetic samples)  \n",
        "$x$: Input data samples  \n",
        "$y$: Conditional information (e.g., class labels, auxiliary data)  \n",
        "$p_r(x|y)$: Conditional probability distribution of real data samples  \n",
        "$p_g(x|y)$: Conditional probability distribution of generated samples  \n",
        "$L(G,D)$: Loss function to be optimized  \n",
        "$\\mathbb{E}$: Expected value operator  \n",
        "\n",
        "**Formula**\n",
        "\n",
        "$$\n",
        "\\min_{G} \\max_{D} L(G,D) = \\mathbb{E}_{x \\sim p_r(x|y)}[\\log(D(x|y))] + \\mathbb{E}_{x \\sim p_g(x|y)}[\\log(1-D(x|y))]\n",
        "$$\n",
        "\n",
        "**Description**\n",
        "\n",
        "The conditional GAN extends the traditional GAN framework by incorporating additional information ($y$) to guide both generation and discrimination processes. In this formulation, both networks operate with awareness of specified conditions, enabling more controlled generation of synthetic data.\n",
        "\n",
        "The discriminator network now evaluates samples while considering the given condition, determining whether a sample is authentic for its specific condition. Meanwhile, the generator creates samples that must align with the provided conditional information, attempting to match the real data distribution for each condition.\n",
        "\n",
        "At theoretical equilibrium, the generator produces samples matching the real data distribution for each condition, while the discriminator's predictions approach 0.5 for both real and generated samples within their respective conditions. This means $p_g(x|y)$ should converge to $p_r(x|y)$ across all valid conditions $y$.\n",
        "\n",
        "This mathematical framework enables precise control over the generation process while maintaining the adversarial training dynamics that make GANs effective for synthetic data generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5753c54a-05b5-490f-af60-568a4a4dd4a0",
      "metadata": {
        "id": "5753c54a-05b5-490f-af60-568a4a4dd4a0"
      },
      "outputs": [],
      "source": [
        "# Define a function to create a conditional discriminator model\n",
        "def get_conditional_discriminator(input_shape=input_shape, num_classes=num_classes, seed=seed):\n",
        "    # Set random seed for reproducibility\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Define input layers for the image and conditioning label\n",
        "    input_layer_image = tfkl.Input(shape=input_shape, name='input_layer_image')\n",
        "    input_layer_conditioning = tfkl.Input(shape=(1,), name='input_layer_conditioning')\n",
        "\n",
        "    # Embed and process the conditioning input\n",
        "    x_c = tfkl.Embedding(num_classes, input_shape[0] * input_shape[1], name='embedding')(input_layer_conditioning)\n",
        "    x_c = tfkl.Flatten(name='flatten')(x_c)\n",
        "    x_c = tfkl.Reshape((input_shape[0], input_shape[1], 1))(x_c)\n",
        "\n",
        "    # Concatenate the conditioning information with the image input\n",
        "    x = tfkl.Concatenate(axis=-1)([input_layer_image, x_c])\n",
        "\n",
        "    # First convolutional block\n",
        "    x = tfkl.Conv2D(32, 4, padding='same', strides=2, name='conv1')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln1')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n",
        "\n",
        "    # Second convolutional block\n",
        "    x = tfkl.Conv2D(64, 4, padding='same', strides=2, name='conv2')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln2')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n",
        "\n",
        "    # Third convolutional block\n",
        "    x = tfkl.Conv2D(128, 4, padding='same', strides=2, name='conv3')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln3')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n",
        "\n",
        "    # Final classification block\n",
        "    x = tfkl.GlobalAveragePooling2D(name='gap')(x)\n",
        "    x = tfkl.Dense(256, name='dense1')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln4')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation4')(x)\n",
        "    output_layer = tfkl.Dense(1, name='dense_out')(x)\n",
        "\n",
        "    # Create and return the conditional discriminator model\n",
        "    return tf.keras.Model(\n",
        "        inputs=[input_layer_image, input_layer_conditioning],\n",
        "        outputs=output_layer,\n",
        "        name='conditional_discriminator'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6254612-c776-493e-9fa6-f538b1924428",
      "metadata": {
        "id": "d6254612-c776-493e-9fa6-f538b1924428"
      },
      "outputs": [],
      "source": [
        "# Instantiate the conditional discriminator model\n",
        "conditional_discriminator = get_conditional_discriminator()\n",
        "\n",
        "# Print a detailed summary of the conditional discriminator\n",
        "conditional_discriminator.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "# Generate and display a graphical representation of the conditional discriminator architecture\n",
        "tf.keras.utils.plot_model(\n",
        "    conditional_discriminator,\n",
        "    show_trainable=True,\n",
        "    expand_nested=True,\n",
        "    dpi=70\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a50ae00-f050-4636-ad06-456d3c7defef",
      "metadata": {
        "id": "3a50ae00-f050-4636-ad06-456d3c7defef"
      },
      "outputs": [],
      "source": [
        "# Define a function to create a conditional generator model\n",
        "def get_conditional_generator(input_shape=(latent_dim,), num_classes=num_classes, seed=seed):\n",
        "    # Set random seed for reproducibility\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Define input layers for noise vector and conditioning label\n",
        "    input_layer_noise = tfkl.Input(shape=input_shape, name='input_layer_noise')\n",
        "    input_layer_conditioning = tfkl.Input(shape=(1,), name='input_layer_conditioning')\n",
        "\n",
        "    # Embed and process the conditioning input\n",
        "    x_c = tfkl.Embedding(num_classes, 32, name='embedding')(input_layer_conditioning)\n",
        "    x_c = tfkl.Flatten(name='flatten')(x_c)\n",
        "\n",
        "    # Concatenate noise vector and label embedding\n",
        "    x = tfkl.Concatenate(axis=-1)([input_layer_noise, x_c])\n",
        "\n",
        "    # Build the generator network\n",
        "    x = tfkl.Dense(4 * 4 * 64, use_bias=False, name='dense0')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln0')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation0')(x)\n",
        "    x = tfkl.Reshape((4, 4, 64))(x)\n",
        "\n",
        "    x = tfkl.UpSampling2D(name='upsampling1')(x)\n",
        "    x = tfkl.Conv2D(64, 3, padding='same', use_bias=False, name='conv1')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln1')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation1')(x)\n",
        "\n",
        "    x = tfkl.UpSampling2D(name='upsampling2')(x)\n",
        "    x = tfkl.Conv2D(128, 3, padding='same', use_bias=False, name='conv2')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln2')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation2')(x)\n",
        "\n",
        "    x = tfkl.UpSampling2D(name='upsampling3')(x)\n",
        "    x = tfkl.Conv2D(256, 3, padding='same', use_bias=False, name='conv3')(x)\n",
        "    x = tfkl.LayerNormalization(name='ln3')(x)\n",
        "    x = tfkl.LeakyReLU(alpha=0.2, name='activation3')(x)\n",
        "\n",
        "    x = tfkl.Conv2D(1, 3, padding='same', use_bias=False, name='conv_out')(x)\n",
        "    output_layer = tfkl.Activation('tanh', name='activation_out')(x)\n",
        "\n",
        "    # Create and return the conditional generator model\n",
        "    return tf.keras.Model(\n",
        "        inputs=[input_layer_noise, input_layer_conditioning],\n",
        "        outputs=output_layer,\n",
        "        name='conditional_generator'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32faa0d-7262-41b8-b38b-34cf4cbce813",
      "metadata": {
        "id": "f32faa0d-7262-41b8-b38b-34cf4cbce813"
      },
      "outputs": [],
      "source": [
        "# Instantiate the conditional generator model\n",
        "conditional_generator = get_conditional_generator()\n",
        "\n",
        "# Print a detailed summary of the conditional generator\n",
        "conditional_generator.summary(expand_nested=True, show_trainable=True)\n",
        "\n",
        "# Generate and display a graphical representation of the conditional generator architecture\n",
        "tf.keras.utils.plot_model(\n",
        "    conditional_generator,\n",
        "    show_trainable=True,\n",
        "    expand_nested=True,\n",
        "    dpi=70\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9659e640-3635-4e66-be7a-f70e04995637",
      "metadata": {
        "id": "9659e640-3635-4e66-be7a-f70e04995637"
      },
      "outputs": [],
      "source": [
        "# Define a conditional GAN (cGAN) class inheriting from tf.keras.Model\n",
        "class cGAN(tfk.Model):\n",
        "\n",
        "    # Initialise the cGAN with a discriminator, generator, latent dimension, and discriminator update frequency\n",
        "    def __init__(self, discriminator, generator, latent_dim, n_discriminator_updates=3):\n",
        "        super(cGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "        self.n_discriminator_updates = n_discriminator_updates\n",
        "\n",
        "        # Initialise loss trackers for discriminator and generator\n",
        "        self.d_loss_tracker = tfk.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = tfk.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    # Compile the cGAN with optimisers and an optional loss function\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn=None):\n",
        "        super(cGAN, self).compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn or tfk.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "    # Define cGAN metrics\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_tracker, self.g_loss_tracker]\n",
        "\n",
        "    # Compute generator loss\n",
        "    def _generator_loss(self, fake_output):\n",
        "        return self.loss_fn(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "    # Compute discriminator loss\n",
        "    def _discriminator_loss(self, real_output, fake_output):\n",
        "        real_loss = self.loss_fn(tf.ones_like(real_output), real_output)\n",
        "        fake_loss = self.loss_fn(tf.zeros_like(fake_output), fake_output)\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    # Define the training step\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data into images and labels\n",
        "        real_images, class_labels = data\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "\n",
        "        # Train discriminator multiple times\n",
        "        d_loss = 0\n",
        "        for _ in range(self.n_discriminator_updates):\n",
        "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Generate fake images\n",
        "                generated_images = self.generator([random_latent_vectors, class_labels], training=True)\n",
        "\n",
        "                # Get discriminator outputs for real and fake images\n",
        "                real_output = self.discriminator([real_images, class_labels], training=True)\n",
        "                fake_output = self.discriminator([generated_images, class_labels], training=True)\n",
        "\n",
        "                # Calculate discriminator loss\n",
        "                current_d_loss = self._discriminator_loss(real_output, fake_output)\n",
        "\n",
        "            # Apply discriminator gradients\n",
        "            grads = tape.gradient(current_d_loss, self.discriminator.trainable_weights)\n",
        "            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "            d_loss += current_d_loss / self.n_discriminator_updates\n",
        "\n",
        "        # Train generator\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Generate fake images\n",
        "            generated_images = self.generator([random_latent_vectors, class_labels], training=True)\n",
        "\n",
        "            # Get discriminator output for fake images\n",
        "            fake_output = self.discriminator([generated_images, class_labels], training=False)\n",
        "\n",
        "            # Calculate generator loss\n",
        "            g_loss = self._generator_loss(fake_output)\n",
        "\n",
        "        # Apply generator gradients\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update loss trackers\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "\n",
        "        # Return loss metrics\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_tracker.result(),\n",
        "            \"g_loss\": self.g_loss_tracker.result()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd688bb5",
      "metadata": {
        "id": "bd688bb5"
      },
      "outputs": [],
      "source": [
        "# Define a callback for monitoring conditional GAN training progress\n",
        "class ConditionalGANMonitor(tfk.callbacks.Callback):\n",
        "\n",
        "    # Initialise the callback with the number of images, classes, latent dimension, and display options\n",
        "    def __init__(self, num_img=10, num_classes=10, latent_dim=latent_dim, name='', gray=False):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "        self.name = name\n",
        "        self.gray = gray\n",
        "\n",
        "    # Generate and display images at the end of each epoch\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Set random seed for reproducibility\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "        # Ensure output directory exists\n",
        "        os.makedirs(self.name + 'temp', exist_ok=True)\n",
        "\n",
        "        # Generate random latent vectors and class labels\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        labels = tf.cast(tf.math.floormod(tf.range(0, self.num_img), self.num_classes), 'float32')\n",
        "\n",
        "        # Generate images using the model's generator\n",
        "        generated_images = self.model.generator([random_latent_vectors, labels]).numpy()\n",
        "\n",
        "        # Plot the generated images\n",
        "        fig, axes = plt.subplots(1, self.num_img, figsize=(20, 2 * self.num_img))\n",
        "        for i in range(self.num_img):\n",
        "            img = tfk.preprocessing.image.array_to_img(generated_images[i])\n",
        "            ax = axes[i % self.num_img]\n",
        "            if self.gray:\n",
        "                ax.imshow(np.squeeze(img), cmap='gray')\n",
        "            else:\n",
        "                ax.imshow(np.squeeze(img))\n",
        "            ax.axis('off')\n",
        "\n",
        "        # Adjust layout and display the plot\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4b4d6a4",
      "metadata": {
        "id": "f4b4d6a4"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the conditional GAN (cGAN) with specified discriminator, generator, and latent dimension\n",
        "cgan = cGAN(\n",
        "    discriminator=get_conditional_discriminator(),\n",
        "    generator=get_conditional_generator(),\n",
        "    latent_dim=latent_dim\n",
        ")\n",
        "\n",
        "# Compile the cGAN with Adam optimisers for both discriminator and generator\n",
        "cgan.compile(\n",
        "    d_optimizer=tfk.optimizers.AdamW(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999),\n",
        "    g_optimizer=tfk.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5, beta_2=0.999)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b937688",
      "metadata": {
        "id": "9b937688"
      },
      "outputs": [],
      "source": [
        "# Generate and display conditional samples from a model\n",
        "def conditional_sample(model, num_img, latent_dim, num_classes=10, fixed=True, gray=False, label=None):\n",
        "    # Optionally set a fixed random seed for reproducibility\n",
        "    if fixed:\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "    # Generate random latent vectors\n",
        "    z = tf.random.normal(shape=(num_img, latent_dim))\n",
        "\n",
        "    # Generate class labels or use the specified label\n",
        "    if label is None:\n",
        "        labels = tf.cast(tf.math.floormod(tf.range(0, num_img), num_classes), 'int32')\n",
        "    else:\n",
        "        labels = tf.cast(tf.math.floormod(tf.ones(num_img) * label, num_classes), 'int32')\n",
        "\n",
        "    # Reshape labels to match the expected input shape\n",
        "    labels = tf.reshape(labels, (-1, 1))\n",
        "\n",
        "    # Generate images using the model\n",
        "    generated_images = model([z, labels]).numpy()\n",
        "\n",
        "    # Display the generated images\n",
        "    fig, axes = plt.subplots(1, num_img, figsize=(20, 2 * num_img))\n",
        "    for i in range(num_img):\n",
        "        img = tfk.preprocessing.image.array_to_img(generated_images[i])\n",
        "        ax = axes[i % num_img]\n",
        "        if gray:\n",
        "            ax.imshow(np.squeeze(img), cmap='gray')\n",
        "        else:\n",
        "            ax.imshow(np.squeeze(img))\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate a conditional dataset of images and labels\n",
        "def generate_conditional_dataset(model, num_img, latent_dim, fixed=True, label=None):\n",
        "    # Optionally set a fixed random seed for reproducibility\n",
        "    if fixed:\n",
        "        tf.random.set_seed(seed)\n",
        "\n",
        "    # Generate random latent vectors\n",
        "    z = tf.random.normal(shape=(num_img, latent_dim))\n",
        "\n",
        "    # Generate class labels or use the specified label\n",
        "    if label is None:\n",
        "        labels = tf.cast(tf.math.floormod(tf.range(0, num_img), num_classes), 'int32')\n",
        "    else:\n",
        "        labels = tf.cast(tf.math.floormod(tf.ones(num_img) * label, num_classes), 'int32')\n",
        "\n",
        "    # Reshape labels to match the expected input shape\n",
        "    labels = tf.reshape(labels, (-1, 1))\n",
        "\n",
        "    # Generate images using the model\n",
        "    generated_images = model([z, labels]).numpy()\n",
        "\n",
        "    # Return the generated dataset and corresponding labels\n",
        "    return generated_images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fbcc87",
      "metadata": {
        "id": "66fbcc87"
      },
      "outputs": [],
      "source": [
        "# Generate and display 10 conditional samples using the cGAN generator\n",
        "# Display the images in grayscale\n",
        "conditional_sample(cgan.generator, 10, latent_dim, gray=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ada4c49",
      "metadata": {
        "id": "8ada4c49",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Train the conditional GAN model with the dataset and specified parameters\n",
        "c_history = cgan.fit(\n",
        "    X,\n",
        "    y,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[ConditionalGANMonitor(name='fashionmnist_cgan', gray=True)],\n",
        "    verbose=2\n",
        ").history\n",
        "\n",
        "# Save the trained conditional GAN generator model\n",
        "cgan.generator.save('fashionmnist_cgan.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02b804e1",
      "metadata": {
        "id": "02b804e1"
      },
      "outputs": [],
      "source": [
        "# Plot the discriminator loss during training\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(c_history['d_loss'], label='Discriminator loss', alpha=0.8, linewidth=3)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Plot the generator loss during training\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(c_history['g_loss'], label='Generator loss', alpha=0.8, linewidth=3)\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Display the plots\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üïπÔ∏è Use the Model - Make Inference"
      ],
      "metadata": {
        "id": "tqyYDPxXX4Np"
      },
      "id": "tqyYDPxXX4Np"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee1a52f",
      "metadata": {
        "id": "4ee1a52f"
      },
      "outputs": [],
      "source": [
        "# Load the saved conditional GAN generator model\n",
        "conditional_gan_generator = tfk.models.load_model('fashionmnist_cgan.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f889da01",
      "metadata": {
        "id": "f889da01"
      },
      "outputs": [],
      "source": [
        "# Generate and display 10 conditional samples using the loaded conditional GAN generator\n",
        "# Disable fixed random seed and display images in grayscale for both invocations\n",
        "conditional_sample(conditional_gan_generator, 10, latent_dim, fixed=False, gray=True)\n",
        "conditional_sample(conditional_gan_generator, 10, latent_dim, fixed=False, gray=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bc3ecb",
      "metadata": {
        "id": "36bc3ecb"
      },
      "outputs": [],
      "source": [
        "# Generate and display 10 conditional samples for each class using the loaded conditional GAN generator\n",
        "# Disable fixed random seed and display images in grayscale for each class\n",
        "for i in range(num_classes):\n",
        "    conditional_sample(conditional_gan_generator, 10, latent_dim, gray=True, fixed=False, label=i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TN984I5YeY-5",
      "metadata": {
        "id": "TN984I5YeY-5"
      },
      "source": [
        "#  \n",
        "<img src=\"https://airlab.deib.polimi.it/wp-content/uploads/2019/07/airlab-logo-new_cropped.png\" width=\"350\">\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Instagram_logo_2022.svg/800px-Instagram_logo_2022.svg.png\" width=\"15\"> **Instagram:** https://www.instagram.com/airlab_polimi/\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/81/LinkedIn_icon.svg/2048px-LinkedIn_icon.svg.png\" width=\"15\"> **LinkedIn:** https://www.linkedin.com/company/airlab-polimi/\n",
        "___\n",
        "Credits: Eugenio Lomurno üìß eugenio.lomurno@polimi.it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "   Copyright 2024 Eugenio Lomurno\n",
        "\n",
        "   Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "   you may not use this file except in compliance with the License.\n",
        "   You may obtain a copy of the License at\n",
        "\n",
        "       http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "   Unless required by applicable law or agreed to in writing, software\n",
        "   distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "   See the License for the specific language governing permissions and\n",
        "   limitations under the License.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}